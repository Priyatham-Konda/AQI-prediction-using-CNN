{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvwVR5lHA8q_"
      },
      "source": [
        "## Download and Prepare the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "metadata": {
        "id": "85xL7XLG2BN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PQJkaMlF2Evb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "wiS9yYVy2Lh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "WbB8mh2M2MVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "5KLOHdUh25O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download adarshrouniyar/air-pollution-image-dataset-from-india-and-nepal/"
      ],
      "metadata": {
        "id": "8qSS6qG229_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrxdR83ANgjS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_zip_file_path.zip' with the actual path of your zip file\n",
        "zip_file_path = '/content/air-pollution-image-dataset-from-india-and-nepal.zip'\n",
        "\n",
        "# Extract the zip file to the current working directory\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# List the contents of the current working directory\n",
        "extracted_files = os.listdir('/content/')\n",
        "print(\"Files extracted successfully:\", extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp9dLel9N9DS"
      },
      "outputs": [],
      "source": [
        "  # Create a new directory for extraction\n",
        "extraction_path = '/content/dataset'\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file to the specified directory\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# List the contents of the extraction directory\n",
        "extracted_files = os.listdir(extraction_path)\n",
        "print(\"Files extracted successfully:\", extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the original dataset\n",
        "original_dataset_path = '/content/dataset/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/IND_and_NEP'\n",
        "\n",
        "# Path to the new train and validation folders\n",
        "output_train_path = '/content/dataset/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/Train'\n",
        "output_validation_path = '/content/dataset/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/Validation'\n",
        "\n",
        "# Create train and validation folders if they don't exist\n",
        "os.makedirs(output_train_path, exist_ok=True)\n",
        "os.makedirs(output_validation_path, exist_ok=True)\n",
        "\n",
        "# Get the list of original folders\n",
        "original_folders = os.listdir(original_dataset_path)\n",
        "\n",
        "# Iterate through each original folder\n",
        "for folder in original_folders:\n",
        "    folder_path = os.path.join(original_dataset_path, folder)\n",
        "\n",
        "    # Get the list of image files in the original folder\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    # Split the dataset into train and validation sets\n",
        "    train_files, validation_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create train and validation folders for the current original folder\n",
        "    output_train_folder = os.path.join(output_train_path, folder)\n",
        "    output_validation_folder = os.path.join(output_validation_path, folder)\n",
        "    os.makedirs(output_train_folder, exist_ok=True)\n",
        "    os.makedirs(output_validation_folder, exist_ok=True)\n",
        "\n",
        "    # Copy training set images to the train folder\n",
        "    for file in train_files:\n",
        "        source_path = os.path.join(folder_path, file)\n",
        "        destination_path = os.path.join(output_train_folder, file)\n",
        "        shutil.copyfile(source_path, destination_path)\n",
        "\n",
        "    # Copy validation set images to the validation folder\n",
        "    for file in validation_files:\n",
        "        source_path = os.path.join(folder_path, file)\n",
        "        destination_path = os.path.join(output_validation_folder, file)\n",
        "        shutil.copyfile(source_path, destination_path)\n",
        "\n",
        "print(\"Dataset split into train and validation successfully.\")\n"
      ],
      "metadata": {
        "id": "Wicr4pBO3GEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa0YF5oCpYw"
      },
      "source": [
        "## CNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgvGg2nsCj-0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OskuZ2ThFqmg"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "## ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWTisYLQM1aM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/content/dataset/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/Train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"/content/dataset/Air Pollution Image Dataset/Air Pollution Image Dataset/Combined_Dataset/Validation\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=32\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orf1QQlGGyOe"
      },
      "source": [
        "## Train the model and evaluate the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHX5L7HFXQ7"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=30, steps_per_epoch=len(train_generator), validation_data = validation_generator, verbose = 1, validation_steps=len(validation_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTRVCr6aosw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('aqidl.h5')"
      ],
      "metadata": {
        "id": "c9_U_yeN5ftO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}